---
author:
- Utku Turk
fontsize: 11pt
geometry:
- top=30mm
- left=20mm
- bottom=20mm
- right=20mm
- heightrounded
mainfont: Gentium Plus
monofont: Hack
monofontoptions: Scale=0.7
sansfont: Gentium Plus
title: Guidelines to Run Montreal Forced Aligner for a PCIbex Experiment
toc-title: Table of contents
---

-   [[1]{.toc-section-number}
    Introduction](#introduction){#toc-introduction}
-   [[2]{.toc-section-number} PCIbex
    Results](#pcibex-results){#toc-pcibex-results}
    -   [[2.1]{.toc-section-number} Read the
        results](#read-the-results){#toc-read-the-results}
    -   [[2.2]{.toc-section-number} Filter the
        results](#filter-the-results){#toc-filter-the-results}
    -   [[2.3]{.toc-section-number} Operators used in this
        section](#operators-used-in-this-section){#toc-operators-used-in-this-section}
    -   [[2.4]{.toc-section-number} Our Task
        List](#our-task-list){#toc-our-task-list}
-   [[3]{.toc-section-number} Filtering Files from the
    Server](#filtering-files-from-the-server){#toc-filtering-files-from-the-server}
    -   [[3.1]{.toc-section-number} Operators used in this
        section](#operators-used-in-this-section-1){#toc-operators-used-in-this-section-1}
    -   [[3.2]{.toc-section-number} Our Task
        List](#our-task-list-1){#toc-our-task-list-1}
-   [[4]{.toc-section-number} Renaming
    Files](#renaming-files){#toc-renaming-files}
    -   [[4.1]{.toc-section-number} One-file
        example](#one-file-example){#toc-one-file-example}
    -   [[4.2]{.toc-section-number} Little treat for
        you](#little-treat-for-you){#toc-little-treat-for-you}
    -   [[4.3]{.toc-section-number} For loop](#for-loop){#toc-for-loop}
    -   [[4.4]{.toc-section-number} Operators used in this
        section](#operators-used-in-this-section-2){#toc-operators-used-in-this-section-2}
    -   [[4.5]{.toc-section-number} Our Task
        List](#our-task-list-2){#toc-our-task-list-2}
-   [[5]{.toc-section-number} Running the Montreal Forced
    Aligner](#running-the-montreal-forced-aligner){#toc-running-the-montreal-forced-aligner}
    -   [[5.1]{.toc-section-number} Moving the Files to MFA
        Directory](#moving-the-files-to-mfa-directory){#toc-moving-the-files-to-mfa-directory}
    -   [[5.2]{.toc-section-number} Terminal
        Codes](#terminal-codes){#toc-terminal-codes}
    -   [[5.3]{.toc-section-number} Our Task
        List](#our-task-list-3){#toc-our-task-list-3}
-   [[6]{.toc-section-number} Dataframe
    Creation](#dataframe-creation){#toc-dataframe-creation}
    -   [[6.1]{.toc-section-number} One-file
        example](#one-file-example-1){#toc-one-file-example-1}
    -   [[6.2]{.toc-section-number} Another Treat for
        you](#another-treat-for-you){#toc-another-treat-for-you}
    -   [[6.3]{.toc-section-number}
        For-loop](#for-loop-1){#toc-for-loop-1}
-   [[7]{.toc-section-number} An Example Descriptive
    Summary](#an-example-descriptive-summary){#toc-an-example-descriptive-summary}

# Introduction {#introduction number="1"}

Let's say we have our data from PCIbex and we also have our zip files
from the server. Let's also say we unzipped them and converted them to
`.wav` files from `.webm` files. Now, it is time to align them using
MFA. But, before that we have to prepare our files accordingly. Here's
the steps that we are going to follow in this document.

-   Load the PCIbex results
-   Filter irrelevant sound files
-   Move all of our `.wav` and `.TextGrid` files to the same directory
-   Rename our files according to MFA guidelines
-   Run MFA
-   Create a dataframe

Before we start everything, let me load my favorite packages.
`library()` loads the packages we want, hopefully they are already
installed. If not, use `install.packages()` function to install these
packages. While `library()` should have them without a quote, you should
use quotes with `install.packages()`,
i.e. `install.packages("tidyverse")`. If it asks you to select a Mirror
from a list, choose a place that is geographically close to you, in your
case UK.

::: cell
``` {.r .cell-code}
library(tidyverse) # I have to have tidyverse
library(stringr) # to manipulate string
library(readtextgrid) # to read TextGrid files
library(dplyr)
```
:::

# PCIbex Results {#pcibex-results number="2"}

## Read the results {#read-the-results number="2.1"}

The main reason we are loading PCIbex results is because sometimes we
can use `async()` function in our PCIbex code. `async()` function allow
us to send recordings to our server whenever we want without waiting the
end of the experiment. Even though it is extremely helpful in allowing
us to decrease some of the server-PCIbex connection load at the end of
experiment, it also creates some pesky situations. For example, if a
participant decides to not complete their experiment, we will still end
up some of their recordings. We do not want participants who were
windows-shopping, mainly because we are not sure about the quality of
their data. Luckily for us, PCIbex only saves the results of
participants who complete the entire experiment.

To read the PCIbex results, we are going to use the function provided to
us in [PCIbex
documentation](https://doc.pcibex.net/advanced-tutorial/12_examining-data.html).
Scroll down in that page, and you will see the words
`Click for Base R Version`. The function is provided there as well.
Moreover, please be careful whenever you are copy pasting your functions
from this file, or any file, sometimes PDF or HTML files can include
something unwanted, like a page number.

::: cell
``` {.r .cell-code}
# User-defined function to read in PCIbex Farm results files
read.pcibex <- function(
    filepath,
    auto.colnames=TRUE,
    fun.col=\(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}
    ) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
         cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}
```
:::

So, now what we have to do is to load our file. I also want to check my
file using `str()` function. Please run `?str` to see what this function
does. For any function that you do not understand, you can run `?`
operator to see the help pages and some examples.

::: cell
``` {.r .cell-code}
ibex <- read.pcibex("~/octo-recall-ibex.csv")
str(ibex)
```

::: {.cell-output .cell-output-stdout}
    'data.frame':   15265 obs. of  24 variables:
     $ Results.reception.time              : int  1716599254 1716599254 1716599254 1716599254 1716599254 1716599254 1716599254 1716599254 1716599254 1716599254 ...
     $ MD5.hash.of.participant.s.IP.address: chr  "eb9865e3e6ad96f9ff9db3a12b5565ae" "eb9865e3e6ad96f9ff9db3a12b5565ae" "eb9865e3e6ad96f9ff9db3a12b5565ae" "eb9865e3e6ad96f9ff9db3a12b5565ae" ...
     $ Controller.name                     : chr  "PennController" "PennController" "PennController" "PennController" ...
     $ Order.number.of.item                : int  1 1 1 1 1 1 1 1 1 1 ...
     $ Inner.element.number                : int  0 0 0 0 0 0 0 0 0 0 ...
     $ Label                               : chr  "consent_form" "consent_form" "consent_form" "consent_form" ...
     $ Latin.Square.Group                  : chr  "NULL" "NULL" "NULL" "NULL" ...
     $ PennElementType                     : chr  "PennController" "PennController" "PennController" "Html" ...
     $ PennElementName                     : chr  "0" "0" "0" "consent" ...
     $ Parameter                           : chr  "_Trial_" "_Header_" "_Header_" "prolificID" ...
     $ Value                               : chr  "Start" "Start" "End" "66481a6d648519a547aebd68" ...
     $ EventTime                           : chr  "1716597822554" "1716597822554" "1716597822554" "1716597873803" ...
     $ w4                                  : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ w3                                  : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ w2                                  : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ w1                                  : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ nw                                  : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ itemnum                             : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ trigger_type                        : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ trigger                             : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ verb_type                           : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ head                                : chr  "undefined" "undefined" "undefined" "undefined" ...
     $ PROLIFIC_ID                         : chr  "66481a6d648519a547aebd68" "66481a6d648519a547aebd68" "66481a6d648519a547aebd68" "66481a6d648519a547aebd68" ...
     $ Comments                            : chr  "NULL" "NULL" "NULL" "text input" ...
:::
:::

Now, what I want to do is to get to filenames that are recorded in the
PCIbex results. Before doing that, I advise you to go to [this
documentation](https://github.com/addrummond/ibex/blob/master/docs/manual.md)
and read more about PCIbex under the Basic Concepts header.

  -------------------------------------------------------------------------
  **Column**   **Information**
  ------------ ------------------------------------------------------------
  1            Time results were received (seconds since Jan 1 1970)

  2            MD5 hash identifying subject. This is based on the subject's
               IP address and various properties of their browser. Together
               with the value of the first column, this value should
               uniquely identify each subject.

  3            Name of the controller for the entity
               (e.g. "DashedSentence")

  4            Item number

  5            Element number

  6            Label. Label of the newTrial()

  7            Latin.Square.Group. The group they are assigned to.

  8            PennElementType. Name of the specific element, like "Html",
               "MediaRecorder"

  9            PennElementName. Name we have given to the specific Penn
               Elements.

  10           Parameter. This is about what type of element the script is
               running and saving as a parameter.

  11           Value. Value saved for the parameters in column 10.

  12           EventTime. Time that specific Element is screened or any
               action taken with that Element (seconds since Jan 1 1970)
  -------------------------------------------------------------------------

## Filter the results {#filter-the-results number="2.2"}

Since we are dealing with media recordings, I will first filter the file
using PennElementType column and will only select rows with
"MediaRecorder" values in that column.

::: cell
``` {.r .cell-code}
ibex <- ibex |> filter(PennElementType == "MediaRecorder")
unique(ibex$Value)[1:3]
```

::: {.cell-output .cell-output-stdout}
    [1] "test-recorder.webm" "1_prac-1_jztb.webm" "2_prac-1_jztb.webm"
:::
:::

After checking my `Value` column where the files names for
`MediaRecorder` is stored, I realize that this will not be enough given
that we still have other unwanted elements like `test-recorder.webm`
file or some practice files. There are multiple ways to get rid of these
files, and you have to think about how to get rid of them for your own
specific dataframe. For my own data, I will filter my data utilizing the
labels I provided in my PCIbex code. They are stored in `Labels` column.
What I want is to only get the `MediaRecorders` that are within a trial
whose label starts with the word `trial`. You may have coded your data
differently; you may have used a different word; you may not even have
any practice or test-recorders, so, maybe you do not even have to this
second filtering. Check your dataframe using the function `View()`. I am
also using a function called `str_detect()`, which detect a regular
expression pattern, in this case `^trial`, meaning starting with the
word trial. Now, when I check my dataframe, I only will see experimental
trials and recordings related to those trials. Just to make sure, I am
also using the `unique()` functions so that I do not have repetitions.
And, I am assigning my filenames to a list called `ibex_files`. You can
see that any random sample with `sample()` function, will give filenames
related to experimental trials.

::: cell
``` {.r .cell-code}
ibex <- ibex |> filter(str_detect(Label, "^trial"))
ibex_files <- ibex$Value |> unique()
sample(ibex_files, 3)
```

::: {.cell-output .cell-output-stdout}
    [1] "penguin_Unaccusative_related_onbc.webm"
    [2] "penguin_Unergative_unrelated_nnjw.webm"
    [3] "clown_Unaccusative_unrelated_nnjw.webm"
:::
:::

## Operators used in this section {#operators-used-in-this-section number="2.3"}

::: function
`?`

Opens the help page for any function.

example use: `?library()`
:::

`<br>`{=html}

::: function
`==`

Test for equality. **Don't confuse with a single =, which is an
assignment operator (and also always returns TRUE).**

example use: \`\`
:::

`<br>`{=html}

::: function
`|>`

*(Forward) pipe:* Use the expression on the left as a part of the
expression on the right.

-   Read `x |> fn()` as *'use `x` as the **only** argument of function
    `fn`'.*
-   Read `x |> fn(1, 2)` as *'use `x` as the **first** argument of
    function `fn`'.*
-   Read `x |> fn(1, ., 2)` as *'use `x` as the **second** argument of
    function `fn`'.*

example use: \`\`
:::

## Our Task List {#our-task-list number="2.4"}

-   ~~Load the PCIbex results~~
-   Filter irrelevant sound files
-   Move all of our `.wav` and `.TextGrid` files to the same directory
-   Rename our files according to MFA guidelines
-   Run MFA
-   Create a dataframe

# Filtering Files from the Server {#filtering-files-from-the-server number="3"}

Now that we have a *gold list*, we can go ahead and filter our files
from the server according to our gold list, based on the results from
PCIbex. To do this, first we will create a temporary folder called
`gold`. We will strip every file name from their extension `.wav` or
`.TextGrid` and check that name exists in our *gold list*. If that is
the case, we will move the file. To this end, we are going to use
something called [*for
loops*](https://www.youtube.com/watch?v=5zOTJ0fOllI) and [*if
statements*](https://www.youtube.com/watch?v=N6E_qqhwr7M). You can click
on the hyperlinks to watch more on them.[^1]

-   First, we need to list all of our files. I have all my `.wav` and
    `.TextGrid` files in the same place, so I just need to list a single
    directory. You might have them in different places. Check the
    commented out part. To only get relevant files, I am using a regular
    expression saying only chose the ones that end (`$`) with `.wav` or
    (`|`) `.TextGrid` using the pattern argument.
-   Second, we create our *gold directory* with `dir.create()` function.
-   Third, we iterate over every file in the files list, get its name
    without its extension using `tools::file_path_sans_ext()` function
    and check whether it exist in our *gold list* using `%in%` operator.
-   If it is also present in the gold_list, we specify where the file
    exists and assign it to a variable called `old_file_path`. We also
    specify where it should be moved and assign it to a variable called
    `new_file_path`. We use `file.path()` function and `dir`/`gold_dir`
    variables, along with the file `f` we are iterating over.
-   Lastly, we move the file using `file.rename()` function. Even though
    the name of the function is *rename*, it can be used to move files.
    Every file exist with its pointer, such as `~/data/important.R`. By
    changing this pointer, we can change its name, as well as its
    location to something like `~/gold_data/really_important.R`. We did
    not only change the file name from important to really_important. We
    also changed other parts of this pointer, that is the folder part.
    If the folder gold_data exists, it will be moved there.
-   To make sure this for loop works, I also print a message after every
    file movement using the function `cat()`.

::: cell
``` {.r .cell-code}
dir <- "~/data"
gold_dir <- "~/data/gold"
# Use these lines if you have sound and transcriptions in different places.
# wav_dir <- "~/wav_data"
# tg_dir <- "~/tg_data"

files <- list.files(data, pattern = "\\.wav$|\\.TextGrid")
# Use these lines if you have sound and transcriptions in different places.
# tg_files <- list.files(wav_dir, pattern = "\\.wav$|\\.TextGrid")
# wav_files <- list.files(tg_dir, pattern = "\\.wav$|\\.TextGrid")

dir.create(gold_dir)

for (f in files) {
  if (tools::file_path_sans_ext(f) %in% tools::file_path_sans_ext(ibex_files)) {
    old_file_path <- file.path(dir, f)
    new_file_path <- file.path(gold_dir, f)
    file.rename(old_file_path, new_file_path)
    cat("Moved ", f, " to ", new_file_path, "\n")
  }
}
```
:::

One important thing to note here is that if you have your `.wav` and
`.TextGrid` files in different directories. You can either manually move
them to a single folder using your Folders application. Or, you can run
the command above using wav_dir and tg_dir variables, along with
tg_files, and wav_files variables. It should look like following. There
are of course way better ways to solve this problem. I am leaving that
to your creativity.

::: cell
``` {.r .cell-code}
wav_dir <- "~/wav_data"
tg_dir <- "~/tg_data"
gold_dir <- "~/data/gold"


tg_files <- list.files(wav_dir, pattern = "\\.wav$|\\.TextGrid")
wav_files <- list.files(tg_dir, pattern = "\\.wav$|\\.TextGrid")

dir.create(gold_dir)

for (f in tg_files) {
  if (tools::file_path_sans_ext(f) %in% tools::file_path_sans_ext(ibex_files)) {
    old_file_path <- file.path(tg_dir, f)
    new_file_path <- file.path(gold_dir, f)
    file.rename(old_file_path, new_file_path)
    cat("Moved", f, "to", new_file_path, "\n")
  }
}

for (f in wav_files) {
  if (tools::file_path_sans_ext(f) %in% tools::file_path_sans_ext(ibex_files)) {
    old_file_path <- file.path(wav_dir, f)
    new_file_path <- file.path(gold_dir, f)
    file.rename(old_file_path, new_file_path)
    cat("Moved", f, "to", new_file_path, "\n")
  }
}
```
:::

## Operators used in this section {#operators-used-in-this-section-1 number="3.1"}

::: function
`%in%`

Test for membership

example use: \`\`
:::

## Our Task List {#our-task-list-1 number="3.2"}

-   ~~Load the PCIbex results~~
-   ~~Filter irrelevant sound files~~
-   ~~Move all of our .wav and .TextGrid files to the same directory~~
-   Rename our files according to MFA guidelines
-   Run MFA
-   Create a dataframe

# Renaming Files {#renaming-files number="4"}

This section is going to be the section you have to be most careful
about. If you mess anything up in this section, you will have to delete
everything, go back, unzip your files, convert them to .wav from .webm,
and do everything in this file again. So, before going giving you the
for-loop to rename all files, I want to make sure that we go over one of
the files, and make sure we do it correctly.

The main reason we rename our files is because we want Montreal Forced
Aligner to understand that we have multiple speakers in our dataset. If
we do not do that, it will treat as if all of the files are from a
single speaker and probably will be very confused due to inter-speaker
variance in speech. Since we have erroneously specified in our PCIbex
files to use the `subject_id` as a suffix, rather than a prefix, we have
to fix that. If in the future, we fix that in our PCIbex script, we do
not have to go over this part.

## One-file example {#one-file-example number="4.1"}

My files after unzipping, converting to `.wav`, and filtering according
to gold list looks like the following. There are some important things
to keep in mind here. First of all, now that everything is in our *gold
directory*, we have to use the `gold_dir` variable to list our files.
Secondly, we again need to use pattern argument to make sure we only
select relevant files. Last thing to beware of in the next code is that
I am using indexing using square brackets to refer to the first elements
in the list. I will use this element to make sure first what I am doing
is correct.

::: cell
``` {.r .cell-code}
gold_dir <- "~/data/gold"
files <- list.files(gold_dir, pattern = "\\.wav$|\\.TextGrid$")
example_file <- files[1]
example_file
```

::: {.cell-output .cell-output-stdout}
    [1] "shota-rep-trial_ballerinaUnacc_sgsg_related_dltc.TextGrid"
:::
:::

### Get the extension and the name {#get-the-extension-and-the-name number="4.1.1"}

Now that we have our name of an example file, we can start cutting it
into smaller pieces to work. Let's first get its extension. We will use
the function `file_ext` from the package called `tools`. Sometimes, we
do not want to load an entire package, but we want to access to a single
function. In those times, we use the operator `::`. In addition to this
function, we use `paste0` to prefix the extension with a dot, so that we
can use it later while we rename our files.

::: cell
``` {.r .cell-code}
extension <- tools::file_ext(example_file)
extension <- paste0(".", extension)
extension
```

::: {.cell-output .cell-output-stdout}
    [1] ".TextGrid"
:::
:::

As for the rest of the name, we will use `file_path_sans_ext()` function
that we used earlier.

::: cell
``` {.r .cell-code}
rest <- tools::file_path_sans_ext(example_file)
rest
```

::: {.cell-output .cell-output-stdout}
    [1] "shota-rep-trial_ballerinaUnacc_sgsg_related_dltc"
:::
:::

### Get the subject id {#get-the-subject-id number="4.1.2"}

Now the most important part is getting the subject name. If you look at
what my `rest` variable returned, you can see that it is the last 4
characters. It is also the last set of characters after the last
underscore. So, there are multiple ways to get to the subject id. I will
show you both so that you can tweak any of those and use with your own
data. For the underscore version, we will use the function
`str_split()`, and for the character counting, we will use `str_sub()`.

#### Underscore approach {#underscore-approach number="4.1.2.1"}

`str_split()` takes a string and splits it according to the separator
you are providing. In our case, the separator is the underscore. We are
also using an additional argument called simplify to make the resulting
element more user-friendly. Our function now returns a small tabular
with 1 row and 5 columns. In order to select the values in the 5th
column, we are using the square brackets again, this time with a comma.
When you use this approach for your own data, remember that you may end
up with less or more than 5 columns, depending on your own naming
convention. Do not forget to change the column number. It might be also
the case that you do not have the subject id stored last or maybe your
separators are not underscore but a simple "-". Change the code
according to your own needs.

::: cell
``` {.r .cell-code}
# Using the underscore information
subj <- str_split(rest, "_", simplify = TRUE)
subj
```

::: {.cell-output .cell-output-stdout}
         [,1]              [,2]             [,3]   [,4]      [,5]
    [1,] "shota-rep-trial" "ballerinaUnacc" "sgsg" "related" "dltc"
:::

``` {.r .cell-code}
subj <- subj[,5]
subj
```

::: {.cell-output .cell-output-stdout}
    [1] "dltc"
:::
:::

Lastly, we have to modify the `rest` variable, so that we do not mark
the subject id twice. I will again use the same approach. After having
the tabular, I will use `paste()` function to put the columns back
together with the separator underscore. Again change how many columns to
be used in this function and the separator according to your own needs.

::: cell
``` {.r .cell-code}
nosubj <- str_split(rest, "_", simplify = TRUE)
nosubj <- paste(nosubj[,1], nosubj[,2], nosubj[,3], nosubj[,4], sep = "_")
nosubj
```

::: {.cell-output .cell-output-stdout}
    [1] "shota-rep-trial_ballerinaUnacc_sgsg_related"
:::
:::

#### Character approach {#character-approach number="4.1.2.2"}

`str_sub()` allows you to subset a part of the string using indices. In
my case, the subject is the last four character. To be able to refer to
the characters from the end, you can use the minus symbol `-`. I specify
`-4` in the start argument, meaning I want extracted string to start
from the fourth character counting back from the end.

::: cell
``` {.r .cell-code}
subj <- str_sub(rest, start = -4)
subj
```

::: {.cell-output .cell-output-stdout}
    [1] "dltc"
:::
:::

To get the rest of the filename, I specify starting point as the `1` and
the endpoint to be `-6`. `-5` would give us the underscore as well.

::: cell
``` {.r .cell-code}
nosubj <- str_sub(rest, start = 1, end = -6)
nosubj
```

::: {.cell-output .cell-output-stdout}
    [1] "shota-rep-trial_ballerinaUnacc_sgsg_related"
:::
:::

### Put the new name and the path together {#put-the-new-name-and-the-path-together number="4.1.3"}

At this point, we have everything we need: (i) the subject id prefix,
(ii) rest of our file name, and (iii) extension. Now, we need to put all
of this together. We are going to use `paste0()` function. Remember this
is different from `paste()` function. The main difference is that with
`paste0()`, we cannot specify the separators, and we have to provide
everything. It seems like a disadvantage at first, but it helps with
non-pattern cases like this.

::: cell
``` {.r .cell-code}
new_name <- paste0(subj, "_", nosubj, extension)
new_name
```

::: {.cell-output .cell-output-stdout}
    [1] "dltc_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid"
:::
:::

We also create a new path to rename our file.

::: cell
``` {.r .cell-code}
new_path <- file.path(gold_dir, new_name)
new_path
```

::: {.cell-output .cell-output-stdout}
    [1] "~/data/gold/dltc_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid"
:::
:::

### Rename the file {#rename-the-file number="4.1.4"}

We are again going to use the `file.rename()` function. This time, we
are only changing the file name and not the path, so the file will not
be moved. We also need to have the full path of our `example_file` as
well. We can easily do that using the `file.path` function again.

::: cell
``` {.r .cell-code}
example_file_path <- file.path(gold_dir, example_file)
example_file_path
```

::: {.cell-output .cell-output-stdout}
    [1] "~/data/gold/shota-rep-trial_ballerinaUnacc_sgsg_related_dltc.TextGrid"
:::
:::

::: cell
``` {.r .cell-code}
file.rename(example_file_path, new_path)
```
:::

After running this, make sure it is the naming convention we want. Go
check your folder, find the trial by searching. It should be something
like `subj_rest.wav` or `subj_rest.TextGrid`. In my case it is
`dltc_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid`, Where the
`dltc` is my subject id or subj.

## Little treat for you {#little-treat-for-you number="4.2"}

I know that some of your files looks like the following:
`squid_S_jtfr.wav`. Here, I will give you to code to rename this. Again,
please check this code before using. First, let's arbitrarily put this
name as a variable. Remember, in your case, you will have this from your
`files` list.

::: cell
``` {.r .cell-code}
example_file <- "squid_S_jtfr.wav"
```
:::

Now, I am going to put all the code together in one chunk, except for
moving. Also, beware that I am using my own `gold_dir`, please specify
according to your own. And, be careful if you are using Windows or Mac.
If you are using Windows your `gold_dir` variable should look like the
second line. I have commented that part with a hashtag/pound symbol.
Uncomment it by deleting the first pound symbol.

::: cell
``` {.r .cell-code}
gold_dir <- "~/data/gold"
# gold_dir <- "C:/Users/utkuturk/data/gold" # for windows
extension <- tools::file_ext(example_file)
extension <- paste0(".", extension)
rest <- tools::file_path_sans_ext(example_file)
subj <- str_sub(rest, start = -4)
nosubj <- str_sub(rest, start = 1, end = -6)
new_name <- paste0(subj, "_", nosubj, extension)
new_path <- file.path(gold_dir, new_name)
new_path
```

::: {.cell-output .cell-output-stdout}
    [1] "~/data/gold/jtfr_squid_S.wav"
:::
:::

This would be your original example file path.

::: cell
``` {.r .cell-code}
example_file_path <- file.path(gold_dir, example_file)
example_file_path
```

::: {.cell-output .cell-output-stdout}
    [1] "~/data/gold/squid_S_jtfr.wav"
:::
:::

And this line would handle the renaming from old `example_file_path` to
the `new_path`, thus the new name.

::: cell
``` {.r .cell-code}
file.rename(example_file_path, new_path)
```
:::

## For loop {#for-loop number="4.3"}

If you made sure that codes above works for you, now you are ready to do
the for loop. We just have to define a variable within the for loop,
something like `f`, and use it instead of `example_file`. This way, we
will iterate over every file in our list. To check whether it is working
properly, I also added a line to print a message every time a file is
renamed.

::: cell
``` {.r .cell-code}
gold_dir <- "~/data/gold"
# gold_dir <- "C:/Users/utkuturk/data/gold" # for windows
files <- list.files(gold_dir, pattern = "\\.wav$|\\.TextGrid$")

for (f in files) {
  extension <- tools::file_ext(f)
  extension <- paste0(".", extension)
  rest <- tools::file_path_sans_ext(f)
  subj <- str_sub(rest, start = -4)
  nosubj <- str_sub(rest, start = 1, end = -6)
  new_name <- paste0(subj, "_", nosubj, extension)
  new_path <- file.path(gold_dir, new_name)
  file_path <- file.path(gold_dir, f)
  file.rename(file_path, new_path)
  cat("Renamed", f, "to", new_name, "\n")
}
```
:::

## Operators used in this section {#operators-used-in-this-section-2 number="4.4"}

::: function
`df[selected_rows, indices_columns] or list[selected_element]`

*\[\], Indexing operator:* Accesses specific rows and/or columns of a
data frame. If it is a list, it only takes a single argument to select
an element. Remember in R indices start with 1, unlike python.

-   `selected_rows` A vector of indices or names.
-   `selected_columns` A vector of indices or names.
-   `selected_element` A vector of indices or names.

example use: `files[1]`
:::

`<br>`{=html}

::: function
`::`

*Double colon operator:* Accesses functions and other objects from
packages. Read `x::y` as *'function y from package x.'*

example use: `tools::file_ext()`
:::

## Our Task List {#our-task-list-2 number="4.5"}

-   ~~Load the PCIbex results~~
-   ~~Filter irrelevant sound files~~
-   ~~Move all of our .wav and .TextGrid files to the same directory~~
-   ~~Rename our files according to MFA guidelines~~
-   Run MFA
-   Create a dataset

# Running the Montreal Forced Aligner {#running-the-montreal-forced-aligner number="5"}

Now that we have our files in the format we want, we can put all of our
files in the MFA folder and start running the aligner. We can either
move our files using the Explorer App and usual copy-paste or we can use
again `file.rename()` function. Due to the limitations of the aligner,
the second option is far better. The main limitation is that MFA starts
creating problems when we give the aligner more than 2000 files at once.
I have a lot of data, so I will use the following function to divide my
files and move them into little subfolders. But before that I will show
you how to move files without dividing them into subfolders.

## Moving the Files to MFA Directory {#moving-the-files-to-mfa-directory number="5.1"}

### Without Dividing {#without-dividing number="5.1.1"}

Again, we are going to use `file.rename()` and `dir.create()` functions
to create the directory we are moving files to and of course to move
files.

::: cell
``` {.r .cell-code}
# gold directory, where all of our files are
gold_dir <- "~/data/gold"
# MFA directory
mfa_dir <- "~/Documents/MFA/mycorpus"
dir.create(mfa_dir)

# Files
files <- list.files(gold_dir, pattern = "\\.wav$|\\.TextGrid$")
for (f in files) {
  old_file_path <- file.path(gold_dir, f)
  mfa_path <- file.path(mfa_dir, f)
  file.rename(old_file_path, mfa_path)
  cat("Moved", f, "to", mfa_dir, "\n")
}
```
:::

### With Dividing them into subfolders {#with-dividing-them-into-subfolders number="5.1.2"}

I will introduce the following function that I use, here I will not go
into details. But it basically does the following steps:

-   Creating a subfolder called `s1` and moving files into it
-   Counting up to 2000
-   When it passes 2000, creating another subfolder by increasing the
    number from `s1` to `s2`.
-   Continues to do so until there are no more files.

::: cell
``` {.r .cell-code}
divide_and_move <- function(source, target, limit=2000) {
  files <- list.files(source, pattern = "\\.wav$|\\.TextGrid$", full.names = TRUE)
  base_names <- unique(tools::file_path_sans_ext(basename(files)))
  s_index <- 1
  f_index <- 0
  s_path <- file.path(target, paste0("s", s_index))
  dir.create(s_path)

  for (b in base_names) {
    rel_files <- files[grepl(paste0("^", b, "\\."), basename(files))]

    if (f_index + length(rel_files) > limit) {
      s_index <- s_index + 1
      s_path <- file.path(target, paste0("s", s_index))
      dir.create(s_path)
      f_index <- 0
    }

    for (f in rel_files) {
      file.rename(f, file.path(s_path, basename(f)))
    }
    f_index <- f_index + length(rel_files)
  }
}
```
:::

You can use this function by just giving the source and the target
folders.

::: cell
``` {.r .cell-code}
# gold directory, where all of our files are
gold_dir <- "~/data/gold"
# MFA directory
mfa_main_dir <- "~/Documents/MFA"
dir.create(mfa_dir)
divide_and_move(gold_dir, mfa_main_dir)
```
:::

## Terminal Codes {#terminal-codes number="5.2"}

After moving the files with either code or by hand to a specific MFA
folder, `~/Documents/MFA`, we can start running the terminal codes. At
this point, I assume you have went over either [MFA
docs](https://montreal-forced-aligner.readthedocs.io/en/latest/installation.html)
to install it. I am also assuming that you have used a `conda`
environment. If you haven't here's the 3 lines to install MFA.

::: cell
::: code-with-filename
**Conda Installation in Terminal**

``` {.bash .cell-code}
conda activate base
conda install -c conda-forge mamba
mamba create -n aligner -c conda-forge montreal-forced-aligner
```
:::
:::

There are again two ways to do this. One way is to either open your
Terminal App or use the Terminal tab in R console below. The other way,
which I like more, is to execute commands using R function `system()`. I
will first go over the easier one, which is using the Terminal App or
the Terminal Tab in R. But the reason I prefer `system()` function is
that I can loop over multiple folders easier that way and I do not have
to run my commands again and again.

### Using Terminal {#using-terminal number="5.2.1"}

The first code we want to run is conda environment code. I have followed
the MFA docs and like them I renamed my environment `aligner`. So, I
start activating that environment.

::: cell
``` {.bash .cell-code}
conda activate aligner
```
:::

After environment activation, I need to download three models: (i) an
acoustic model to recognize the phonemes given the previous and the
following acoustic features (ii) a dictionary to access pretrained
phone-word mappings, and (iii) a g2p model to generate sequence of
phones based on orthography. For all of these models, we are going to
use `english_us_arpa` one. You can look at [this
website](https://mfa-models.readthedocs.io/en/latest/acoustic/index.html)
to check out various languages and various models.

::: cell
``` {.bash .cell-code}
mfa model download acoustic english_us_arpa
mfa model download dictionary english_us_arpa
mfa model download g2p english_us_arpa
```
:::

After downloading these models, we are going to validate our corpus.
There are a lot of customizable parameters for this step. You can check
them
[here](https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/data_validation.html).
I am going to use my favorite ones here. You can read the following code
like this: *Dear Montreal forced aligner (`mfa`), can you please look at
my files in this `~/Documents/MFA/mycorpus` and `validate` them using
`english_us_arpa` acoustic model and `english_us_arpa` dictionary. Can
you also take into consideration that I have multiple speakers and I
have specified them in the first 4 characters (`-s 4`). It would be
awesome to use multiprocessing (`--use_mp`) so it is executed faster.
Lastly, can you clean previous and new temporary files
(`--clean --final_clean`).*

::: cell
``` {.bash .cell-code}
mfa validate -s 4 --use_mp --clean --final_clean ~/Documents/MFA/mycorpus english_us_arpa english_us_arpa
```
:::

This process will take some time. After this, you will have some *out of
vocabulary* words found in your textgrids. You can easily create new
pronounciation for them and add to your model.

The `mfa g2p` command can take many arguments, here I am using only
three. First the path for the text file that has *out of vocabulary*
words. This is automatically created in your folder where your files
are. The path may change depending on your system and your naming of the
folders, but the name of the `.txt` file will be same. In my case it is
`~/Documents/MFA/mycorpus/oovs_found_english_us_arpa.txt`. The second
argument is the g2p model name. As you may remember, we have downloaded
it above, and its name was `english_us_arpa`. And finally, the third
argument is a target `.txt` file to store new pronunciations. I would
like to store them in the same place. So, I am using the following path:
`~/Documents/MFA/mycorpus/g2pped_oovs.txt`.

::: cell
``` {.bash .cell-code}
mfa g2p ~/Documents/MFA/mycorpus/oovs_found_english_us_arpa.txt english_us_arpa ~/Documents/MFA/mycorpus/g2pped_oovs.txt
```
:::

After creating the pronounciations you can add them to your model with
`mfa model add_words`. It takes the name of the dictionary as an
argument `english_us_arpa` and the output of the `mfa g2p` command,
which was a `.txt` file to store pronunciations:
`~/Documents/MFA/mycorpus/g2pped_oovs.txt`

::: cell
``` {.bash .cell-code}
mfa model add_words english_us_arpa ~/Documents/MFA/mycorpus/g2pped_oovs.txt
```
:::

The last step is to aligning step. It will align (`mfa align`) the words
and the phones inside our textgrids stored in `~/Documents/MFA/mycorpus`
using our previously downloaded dictionary (`english_us_arpa`) and model
(`english_us_arpa`), and store new aligned textgrids in a new folder
called `~/Documents/MFA/output`.

::: cell
``` {.bash .cell-code}
mfa align ~/Documents/MFA/mycorpus english_us_arpa english_us_arpa ~/Documents/MFA/output
```
:::

### Using R {#using-r number="5.2.2"}

We can do all of this in R as well. The main plus of this approach is
that it allows us to iterate over multiple subfolders if we have more
than 2000 files easier. We will use four components:

(i) `system()` function to run the terminal commands,
(ii) `paste()` function to create multiline templates,
(iii) `%s` string placehold to create template codes,
(iv) `sprintf()` function to format our templates.

#### Intro to `sprintf()` and `%s` {#intro-to-sprintf-and-s number="5.2.2.1"}

Before going deep into mfa codes, let me show you an example. Let's say
we have a list of foldernames, and we want to create a `.txt` file in
all of these folders. You can use `system()` function to do this action.
Below, I first specify my folder_list, then I create paths for my `.txt`
file in every folder, i.e. `~/data1/mydocument.txt`. Later, I create a
list of commands to create these files,
i.e. `touch ~/data1/mydocument.txt`. `touch` does the magic here. You
can create documents in terminal using `touch`. Then, I ran this list
using the `system()` function.

::: cell
``` {.r .cell-code}
folder_list <- c("~/data1", "~/data2", "~/data3")


txt_list <- paste(folder_list, "mydocument.txt", sep="/")
txt_list
```

::: {.cell-output .cell-output-stdout}
    [1] "~/data1/mydocument.txt" "~/data2/mydocument.txt" "~/data3/mydocument.txt"
:::

``` {.r .cell-code}
command_list <- paste("touch", txt_list, sep=" ")
command_list
```

::: {.cell-output .cell-output-stdout}
    [1] "touch ~/data1/mydocument.txt" "touch ~/data2/mydocument.txt"
    [3] "touch ~/data3/mydocument.txt"
:::

``` {.r .cell-code}
for (command in command_list) {
  system(command)
}
```
:::

Technically, we did not have to the a for loop, and instead we could
have concatenated all of these commands with `;` and run a single system
command. Bash can take multiple commands in a single line when they are
separated by `;`.

::: cell
``` {.r .cell-code}
concatenated_commands <- paste(command_list[1],
                               command_list[2],
                               command_list[3],
                               sep=";")

system(concatenated_commands)
```
:::

We could also do this thing without having a folder list using the `%s`
placeholder and the `sprintf()` function.

::: cell
``` {.r .cell-code}
command_template <- "touch %s/mydocument.txt"
concatenated_commands <- paste(sprintf(command_template, "~/data1"),
                               sprintf(command_template, "~/data2"),
                               sprintf(command_template, "~/data3"),
                               sep=";")

system(concatenated_commands)
```
:::

This version is even more useful when you have multiple placeholders in
the same command. The following command, will replace the first `%s` in
the command template with the first argument, let's say `~/data1` and
the second placeholder with the second `sprintf()` argument, for example
`mydoc1`.

::: cell
``` {.r .cell-code}
command_template <- "touch %s/%s.txt"
concatenated_commands <- paste(sprintf(command_template, "~/data1", "mydoc1"),
                               sprintf(command_template, "~/data2", "mydoc2"),
                               sprintf(command_template, "~/data3", "mydoc3"),
                               sep=";")

system(concatenated_commands)
```
:::

#### Running MFA in R {#running-mfa-in-r number="5.2.2.2"}

What we are going to do now is just have the same code before but
concatenate it using `paste()` and `;`. When necessary, we will add
placeholders. First, I am assigning every line to a new variable, then I
paste them together separated with `;`. Finally, I ran the code using
`system()`. This time, I have the argument `intern = TRUE`, which helps
me save output of the code to an R variable. I mainly do this to check
it later.

::: cell
``` {.r .cell-code}
conda_start <- "conda activate aligner"
get_ac <- "mfa model download acoustic english_us_arpa"
get_dic <- "mfa model download dictionary english_us_arpa"
get_g2p <- "mfa model download g2p english_us_arpa"

mfa_init <- paste(conda_start, get_ac, get_dic, get_g2p, sep = ";")

mfa_init_output <- system(mfa_init, intern = TRUE)
```
:::

After initiating the model, I need to validate. Again, I will use the
same code and paste them together. But remember, sometimes we can have
too many files and we need to use subfolders. For this reason, I am
going to use placeholder `%s` here. Our validation has one placeholder,
for different subfolders to fill in. Our g2p pronunciation creation have
two placeholders, but they are going to be the same. Lastly, we are
going to use single placeholder in our `add_words` variable. Luckily for
us, all of these folders are the same. We can just use the same variable
over and over again.

::: cell
``` {.r .cell-code}
conda_start <- "conda activate aligner"

validate <- "mfa validate -s 4 --use_mp --clean --final_clean ~/Documents/MFA/%s english_us_arpa english_us_arpa"
g2p_words <- "mfa g2p ~/Documents/MFA/%s/oovs_found_english_us_arpa.txt english_us_arpa ~/Documents/MFA/%s/g2pped_oovs.txt"
add_words <- "mfa model add_words english_us_arpa ~/Documents/MFA/%s/g2pped_oovs.txt"

mfa_val <- paste(conda_start, validate, g2p_words, add_words, sep = ";")
```
:::

Since this part takes longer and a lot more stuff can go wrong, I would
like to save all of my outputs in a list. I want to find which folders
there are in my MFA folder. Since my `divide_and_move` function starts
every subfolder with `s` I am using `^s`, meaning starting with
character `s`, to detect relevant folders.

::: cell
``` {.r .cell-code}
output_val <- list()

# Define the base path where folders are located
base_path <- "~/Documents/MFA"
folders <- list.dirs(base_path, recursive = FALSE, full.names = FALSE)
folders <- folders[str_detect(folders, "^s")]

folders
```

::: {.cell-output .cell-output-stdout}
    [1] "s1" "s2" "s3"
:::
:::

Now, we can iterate over this list of folder using a for loop. We first
create a temporary script, with `sprintf()`. Since we have four
placeholders, we need to give the variable for four times. Then, we ran
that current script, and save the output to a `temp_output` variable to
later assign it to specific `output_name` for each folder. We do this
second step with `paste0()` and `assign()` functions.

::: cell
``` {.r .cell-code}
for (f in folders) {
  cur_mfa_val <- sprintf(mfa_val, f, f, f, f)

  temp_output <- system(cur_mfa_val, intern = TRUE)

  output_name <- paste0("output_val_", f)

  assign(output_name, temp_output, envir = .GlobalEnv)
}
```
:::

Now you can go ahead and check the outputs by calling specific variables
like `output_val_s1` or `output_val_s2`. After this step, the only thing
left is to run the aligner. We will again create a template, iterate
over folders, and assign outputs to their name to check. In the
meantime, the bash code will run in the background. Differently from the
last time, now our placeholders will refer to different things an input
folder and a output folder. Luckily, we can use the same output folder
for every subfolder. So, instead of using two placeholders, we are just
going to use a single `%s` placeholder.

::: cell
``` {.r .cell-code}
conda_start <- "conda activate aligner"

align <- "mfa align ~/Documents/MFA/%s english_us_arpa english_us_arpa ~/Documents/MFA/output"

mfa_align <- paste(conda_start, align, sep = ";")

for (f in folders) {
  cur_mfa_align <- sprintf(mfa_align, f)
  temp_output <- system(cur_mfa_align, intern=TRUE)
  output_name <- paste0("output_align_", f)
  assign(output_name, temp_output, envir = .GlobalEnv)
}
```
:::

This for loop completes the MFA aligning. There is only one thing left
to do: creating a dataframe to later work on our data.

## Our Task List {#our-task-list-3 number="5.3"}

-   ~~Load the PCIbex results~~
-   ~~Filter irrelevant sound files~~
-   ~~Move all of our .wav and .TextGrid files to the same directory~~
-   ~~Rename our files according to MFA guidelines~~
-   ~~Run MFA~~
-   Create a dataframe

# Dataframe Creation {#dataframe-creation number="6"}

Now that we have all of our `.TextGrid` files aligned, we can create a
dataframe to later employ statistical analyses on. We are going to use
the `readtextgrid` package. Again, I want to show the process for a
single file first. Later, I will show how to scale this to the entire
directory. Let's start with our directory specification and list of
files. You can see the the first couple of elements of a list or a
dataframe using the function `head()`.

::: cell
``` {.r .cell-code}
# Define the directory and list files
tg_dir <- "~/Documents/MFA/output"
file_list <- list.files(path = tg_dir, pattern = "\\.TextGrid$")
head(file_list, n = 5)
```

::: {.cell-output .cell-output-stdout}
    [1] "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid"
    [2] "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_unrelated.TextGrid"
    [3] "bbnw_shota-rep-trial_ballerinaUnerg_sgsg_related.TextGrid"
    [4] "bbnw_shota-rep-trial_ballerinaUnerg_sgsg_unrelated.TextGrid"
    [5] "bbnw_shota-rep-trial_boyUnacc_sgsg_related.TextGrid"
:::
:::

## One-file example {#one-file-example-1 number="6.1"}

Again, let's have an example file and work on it. I will chose the first
file with `[1]` to work on. First, we will get its full file path. Then,
we are going to use `read_textgrid()` function to have our dataframe for
a single file. I am printing the structure of the dataframe here for you
to see more clearly what we have.

::: cell
``` {.r .cell-code}
example_file <- file_list[1]
file_path <- file.path(tg_dir, example_file)
example_df <- readtextgrid::read_textgrid(file_path)
str(example_df)
```

::: {.cell-output .cell-output-stdout}
    tibble [40 × 10] (S3: tbl_df/tbl/data.frame)
     $ file          : chr [1:40] "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid" "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid" "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid" "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid" ...
     $ tier_num      : num [1:40] 1 1 1 1 1 1 1 1 1 1 ...
     $ tier_name     : chr [1:40] "words" "words" "words" "words" ...
     $ tier_type     : chr [1:40] "IntervalTier" "IntervalTier" "IntervalTier" "IntervalTier" ...
     $ tier_xmin     : num [1:40] 0 0 0 0 0 0 0 0 0 0 ...
     $ tier_xmax     : num [1:40] 5.04 5.04 5.04 5.04 5.04 5.04 5.04 5.04 5.04 5.04 ...
     $ xmin          : num [1:40] 0 1.16 1.24 1.98 2.01 ...
     $ xmax          : num [1:40] 1.16 1.24 1.98 2.01 2.28 ...
     $ text          : chr [1:40] "" "the" "ballerina" "" ...
     $ annotation_num: int [1:40] 1 2 3 4 5 6 7 8 9 10 ...
:::
:::

In this project, which is aligning words, we are interested in only
couple of these columns. We are interested in, of course, the file
identifier (`file`) to identify from which trial the data is coming, the
tier name (`tier_name`) to differentiate between words and phones tier,
the start (`xmin`) and the end (`xmax`)of the interval, and finally the
`text`. I am also not interested in having the file extension in the
`file` identifier. So, first we are going to filter so that we only have
annotated words, then select important columns with `select()`, delete
`.Textgrid` extension, and put the words together so that we see what
the full response is for every trial.

::: cell
``` {.r .cell-code}
example_df <- example_df |>
  # Filter annotated "words" tier
  filter(tier_name == "words" & text != "") |>
  # Select relevant columns
  select(file, xmin, xmax, text, annotation_num) |>
  # Remove .TextGrid and put the response together
  mutate(file = str_remove(file, "\\.TextGrid$"),
         response = paste(text, collapse = " "))

example_df
```
:::

::: cell
::: cell-output-display
  ------------------------------------------------------------------------------------------------------------------------
  file                                                   xmin     xmax text          annotation_num response
  -------------------------------------------------- -------- -------- ----------- ---------------- ----------------------
  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     1.1595   1.2395 the                        2 the ballerina above
                                                                                                    the axe is shrinking

  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     1.2395   1.9795 ballerina                  3 the ballerina above
                                                                                                    the axe is shrinking

  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.0095   2.2795 above                      5 the ballerina above
                                                                                                    the axe is shrinking

  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.2795   2.4295 the                        6 the ballerina above
                                                                                                    the axe is shrinking

  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.4295   2.7795 axe                        7 the ballerina above
                                                                                                    the axe is shrinking

  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.7795   2.8995 is                         8 the ballerina above
                                                                                                    the axe is shrinking

  bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.8995   3.5895 shrinking                  9 the ballerina above
                                                                                                    the axe is shrinking
  ------------------------------------------------------------------------------------------------------------------------
:::
:::

We also need some information about the trial. Luckily, all of our
information is provided in our file name. So, I am going to parse that
name to create a dataframe with more information. I am using a set of
function that all start with `separate_wider_`. The `delim` version uses
a deliminator to split a row of a dataframe. The `regex` version uses
regular expressions to split the data. Finally, the `position` version
uses the number of characters to split the data. I am doing all of this
because of how I initially coded my experiment output in my PCIbex
script. You may need to change this code to process your own data.

::: cell
``` {.r .cell-code}
example_df <- example_df |>
  # split the `file` column into 5 different columns.
  separate_wider_delim(file, "_", names = c("subj", "exp", "headVerb", "NumNum", "sem_type"), cols_remove = F) |>
  # split the headVerb column from the "U" character
  separate_wider_regex(headVerb, c(head = ".*", "U", verb_type = ".*")) |>
  # Add the "U" character back to "Unacc" and "Unerg"s
  mutate(verb_type = paste0("U", verb_type)) |>
  # split the head and distractor numbers.
  separate_wider_position(NumNum, c(head_num = 2, dist_num = 2))

example_df
```
:::

::: cell
::: cell-output-display
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  subj   exp               head        verb_type   head_num   dist_num   sem_type   file                                                   xmin     xmax text          annotation_num response
  ------ ----------------- ----------- ----------- ---------- ---------- ---------- -------------------------------------------------- -------- -------- ----------- ---------------- --------------
  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     1.1595   1.2395 the                        2 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     1.2395   1.9795 ballerina                  3 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.0095   2.2795 above                      5 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.2795   2.4295 the                        6 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.4295   2.7795 axe                        7 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.7795   2.8995 is                         8 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.8995   3.5895 shrinking                  9 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
:::
:::

## Another Treat for you {#another-treat-for-you number="6.2"}

Let's see what you will need to do. You will your file in `MFA/output`
folder as well and your file will look like `jtfr_squid_S.TextGrid`.
Let's arbitrarily put them here. Remember, you will have to use
`file.list()` function as well. You will not need to change anything in
the first part where we work on the textgrid. The necessary changes will
need to be done in parsing procedure. Instead of doing the entire
`regex` or `position` things, you will just need the `delim` version of
the function.

::: cell
``` {.r .cell-code}
# Define the directory and list files
tg_dir <- "~/Documents/MFA/output"
your_file <- "jtfr_squid_S.TextGrid"

file_path <- file.path(tg_dir, your_file)


### LETS SAY YOU RAN read_textgrid function.
### I commented out this part, because I do not have your data.
### Final dataframe will be slightly different here, because I do not have the textgrid data here.
# your_df <- readtextgrid::read_textgrid(path = file_path) |>
#     filter(tier_name == "words" & text != "") |>
#     select(file, xmin, xmax, text, annotation_num) |>
#     mutate(file = str_remove(file, "\\.TextGrid$"),
#            response = paste(text, collapse = " "))
#

your_df <- your_df |>
  separate_wider_delim(file, "_", names = c("subj", "head", "condition"), cols_remove = F)

your_df
```
:::

::: cell
::: cell-output-display
  -------------------------------------------------------------------------------------------------------
  subj   head    condition   file           xmin   xmax   text       annotation_num response
  ------ ------- ----------- -------------- ------ ------ -------- ---------------- ---------------------
  jtfr   squid   S           jtfr_squid_S                 squid                   1 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 jumped                  2 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 over                    3 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 the                     4 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 fence                   5 squid jumped over the
                                                                                    fence
  -------------------------------------------------------------------------------------------------------
:::
:::

## For-loop {#for-loop-1 number="6.3"}

Now, we have to do this for all of our files in our output directory. To
do this easier, I want to first create a function for the single-file
process, and apply it to all files. My function takes a file name and
the directory of the file, and returns a dataframe. Before every
dataframe creation, it prints out "Reading the file." line.

::: cell
``` {.r .cell-code}
process_textgrid <- function(file, directory) {
  cat("Reading", file, "\n")
  file_path <- file.path(directory, file)
  df <- readtextgrid::read_textgrid(path = file_path) |>
    filter(tier_name == "words" & text != "") |>
    select(file, xmin, xmax, text, annotation_num) |>
    mutate(file = str_remove(file, "\\.TextGrid$"),
           response = paste(text, collapse = " "))

  df <- df |>
    separate_wider_delim(file, "_", names = c("subj", "exp", "headVerb", "NumNum", "sem_type"), cols_remove = F) |>
    separate_wider_regex(headVerb, c(head = ".*", "U", verb_type = ".*")) |>
    mutate(verb_type = paste0("U", verb_type)) |>
    separate_wider_position(NumNum, c(head_num = 2, dist_num = 2))

  return(df)
}
```
:::

It is exactly the same thing we did above, but in a function version.
Now I can do the same thing easier, for example see the code below. I am
redefining my directory and my file list again, just in case.

::: cell
``` {.r .cell-code}
# Define the directory and list files
tg_dir <- "~/Documents/MFA/output"
file_list <- list.files(path = tg_dir, pattern = "\\.TextGrid$")
example_file <- file_list[1]
process_textgrid(example_file, tg_dir)
```
:::

::: cell
::: {.cell-output .cell-output-stdout}
    Reading bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related.TextGrid
:::

::: cell-output-display
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  subj   exp               head        verb_type   head_num   dist_num   sem_type   file                                                   xmin     xmax text          annotation_num response
  ------ ----------------- ----------- ----------- ---------- ---------- ---------- -------------------------------------------------- -------- -------- ----------- ---------------- --------------
  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     1.1595   1.2395 the                        2 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     1.2395   1.9795 ballerina                  3 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.0095   2.2795 above                      5 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.2795   2.4295 the                        6 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.4295   2.7795 axe                        7 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.7795   2.8995 is                         8 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking

  bbnw   shota-rep-trial   ballerina   Unacc       sg         sg         related    bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related     2.8995   3.5895 shrinking                  9 the ballerina
                                                                                                                                                                                      above the axe
                                                                                                                                                                                      is shrinking
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
:::
:::

Your version will look like this.

::: cell
``` {.r .cell-code}
process_textgrid <- function(file, directory) {
  cat("Reading", file, "\n")
  file_path <- file.path(directory, file)
  df <- readtextgrid::read_textgrid(path = file_path) |>
    filter(tier_name == "words" & text != "") |>
    select(file, xmin, xmax, text, annotation_num) |>
    mutate(file = str_remove(file, "\\.TextGrid$"),
           response = paste(text, collapse = " "))

  df <- df |>
    separate_wider_delim(file, "_", names = c("subj", "head", "condition"), cols_remove = F)

  return(df)
}
```
:::

::: cell
``` {.r .cell-code}
# Define the directory and list files
tg_dir <- "~/Documents/MFA/output"
file_list <- list.files(path = tg_dir, pattern = "\\.TextGrid$")
example_file <- file_list[1]
process_textgrid(example_file, tg_dir)
```
:::

::: cell
::: cell-output-display
  -------------------------------------------------------------------------------------------------------
  subj   head    condition   file           xmin   xmax   text       annotation_num response
  ------ ------- ----------- -------------- ------ ------ -------- ---------------- ---------------------
  jtfr   squid   S           jtfr_squid_S                 squid                   1 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 jumped                  2 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 over                    3 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 the                     4 squid jumped over the
                                                                                    fence

  jtfr   squid   S           jtfr_squid_S                 fence                   5 squid jumped over the
                                                                                    fence
  -------------------------------------------------------------------------------------------------------
:::
:::

Now, we have to integrate this function in our for-loop. Instead of
using a single file like `file_list[1]`, we will need to use an entire
directory. Differently from previous for loops, we are going to use the
function `map` from the package `purrr`. It is faster and in cases like
this easier to use. It will return all of our dataframes embedded in a
list. After `map()`, we have to bind all of these smaller dataframes
into a bigger one using `bind_rows`.

::: cell
``` {.r .cell-code}
# Define the directory and list files
tg_dir <- "~/Documents/MFA/output"
file_list <- list.files(path = tg_dir, pattern = "\\.TextGrid$")
# Run our function, I am using mine, you should use your own.
process_textgrid <- function(file, directory) {
  cat("Reading", file, "\n")
  file_path <- file.path(directory, file)
  df <- readtextgrid::read_textgrid(path = file_path) |>
    filter(tier_name == "words" & text != "") |>
    select(file, xmin, xmax, text, annotation_num) |>
    mutate(file = str_remove(file, "\\.TextGrid$"),
           response = paste(text, collapse = " "))

  df <- df |>
    separate_wider_delim(file, "_", names = c("subj", "exp", "headVerb", "NumNum", "sem_type"), cols_remove = F) |>
    separate_wider_regex(headVerb, c(head = ".*", "U", verb_type = ".*")) |>
    mutate(verb_type = paste0("U", verb_type)) |>
    separate_wider_position(NumNum, c(head_num = 2, dist_num = 2))

  return(df)
}

dfs <- map(file_list, process_textgrid, directory = tg_dir)

final_df <- bind_rows(dfs)
```
:::

This completes our MFA Aligning work. We succesfully went over every
task in our list, aligned our data, and created a dataframe to work on.
You can check our final dataframe's structure, its number of rows, the
number of unique trials.

::: cell
``` {.r .cell-code}
str(final_df)
```

::: {.cell-output .cell-output-stdout}
    tibble [7,000 × 13] (S3: tbl_df/tbl/data.frame)
     $ subj          : chr [1:7000] "bbnw" "bbnw" "bbnw" "bbnw" ...
     $ exp           : chr [1:7000] "shota-rep-trial" "shota-rep-trial" "shota-rep-trial" "shota-rep-trial" ...
     $ head          : chr [1:7000] "ballerina" "ballerina" "ballerina" "ballerina" ...
     $ verb_type     : chr [1:7000] "Unacc" "Unacc" "Unacc" "Unacc" ...
     $ head_num      : chr [1:7000] "sg" "sg" "sg" "sg" ...
     $ dist_num      : chr [1:7000] "sg" "sg" "sg" "sg" ...
     $ sem_type      : chr [1:7000] "related" "related" "related" "related" ...
     $ file          : chr [1:7000] "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related" "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related" "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related" "bbnw_shota-rep-trial_ballerinaUnacc_sgsg_related" ...
     $ xmin          : num [1:7000] 1.16 1.24 2.01 2.28 2.43 ...
     $ xmax          : num [1:7000] 1.24 1.98 2.28 2.43 2.78 ...
     $ text          : chr [1:7000] "the" "ballerina" "above" "the" ...
     $ annotation_num: int [1:7000] 2 3 5 6 7 8 9 2 3 5 ...
     $ response      : chr [1:7000] "the ballerina above the axe is shrinking" "the ballerina above the axe is shrinking" "the ballerina above the axe is shrinking" "the ballerina above the axe is shrinking" ...
:::

``` {.r .cell-code}
nrow(final_df)
```

::: {.cell-output .cell-output-stdout}
    [1] 7000
:::

``` {.r .cell-code}
length(unique(final_df$file))
```

::: {.cell-output .cell-output-stdout}
    [1] 1000
:::
:::

# An Example Descriptive Summary {#an-example-descriptive-summary number="7"}

Let me also show a small example descriptive stats using basic
functions. One thing that we might want to do is to check whether there
is a difference between conditions and people's time to start uttering
the sentence. And, let's assume people are still thinking about the
sentence when they utter the first determiner *the*, since it is kind of
automatic in English and all of our sentences starts with this
determiner anyway. I am going to filter my dataframe using the `text`
column. I also want to make sure that it is the first *the*, and not the
any other *the* in the sentences. So, I will use the `annotation_num`
column as well in my filtering.

::: cell
``` {.r .cell-code}
first_thes <- final_df |> filter(text == "the" & annotation_num < 3)
```
:::

Then, what I am going to do is to summarize my dataframe. I will group
my dataframe by `verb_type` and `sem_type` columns since my experiment
had 2 different verb types (unergatives, unaccusatives) and 2 different
type of semantic distractors (related, unrelated). Then, I am going to
use the `summarize()` function to get the mean and standard error for
each condition. Since we are assuming people are still planning
sentences while they utter the first determiner, I am going to summarize
my data using the offset of the *the* (`xmax`). Before doing this, I am
going to convert `xmax` from seconds to milliseconds.

::: cell
``` {.r .cell-code}
first_thes |>
  mutate(xmax = xmax*1000) |>
  group_by(verb_type, sem_type) |>
  summarize(mean = mean(xmax),
            n = n(),
            stderror = sd(xmax)/n)
```
:::

::: cell
::: cell-output-display
  verb_type   sem_type          mean     n    sterror
  ----------- ----------- ---------- ----- ----------
  Unacc       related       1239.664   244   1.832545
  Unacc       unrelated     1177.799   241   1.660041
  Unerg       related       1211.286   252   1.708245
  Unerg       unrelated     1199.120   263   1.469094
:::
:::

From this point, I am leaving the modeling and the plotting of the data
for another guide.

[^1]: On principle, I am against for loops in R, but it is better to use
    here instead of confusing you more.
